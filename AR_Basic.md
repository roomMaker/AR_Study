# AR_Study

ARCore 기본 개념 읽어보기

포즈 => 위치와 방향 

# 모션추적 (Motion tracking)
휴대전화를 움직일 경우 ARCore는 *동시 현지화 및 매핑(SLAM) 이라는 프로세스를 사용하여 
휴대전화가 주변 세상과 비교하여 어디에 있는지 파악한다.

*이 링크 참고.. 하지만 봐도 모르겠는걸.. 
https://en.wikipedia.org/wiki/Simultaneous_localization_and_mapping

ARCore는 '지점' 이라고 하는 캡처된 카메라 이미지에서 시각적으로 구별되는 지형지물을 감지하고 
이러한 지점(즉 시각적으로 구별되는 특정 지형지물)을 사용하여 위치 변경을 계산한다고 한다.

본문 내용을 그대로 작성하여 
`이 시각적 정보는 기기의 IMU(기울기센서)에 있는 공기 측정값과 결합되어 시간이 지남에 따라 전 세계의 상대적인 포즈를 추정한다.` 
라고 되어있는데 현재는 공기 측정값과 결합되어 포즈를 추정한다는 것이 잘 이해되지 않는다.

당연하게도, ARCore가 제공하는 가상 콘텐츠는 기기의 카메라에서 가져온 이미지 위에 오버레이되어 가상 콘텐츠가 실제 환경의 일부인 것처럼 표시된다.

# 환경 이해 (Environmental understanding)
ARCore는 테이블이나 벽과 같이 일반적인 수평 또는 수직 표면에 놓인 것처럼 보이는 특징점의 클러스터를 찾아 이러한 표면을 기하학적 평면으로 제공합니다. 
=>  일반적으로 '평면'으로 보이는 물체를 인식하여 기하학적 평면으로 제공한다. 라고 이해하면 될 것 같다.

또한 ARCore는 각 기하학적 영역의 경계를 결정하여, 그 정보를 앱에 제공함으로써 그 정보를 사용해 가상 표면을 평평한 표면에 배치할 수 있다고 함.

특징점을 사용해 평면을 감지하므로 흰색 벽과 같은 질감이 없는 평평한 표면이 제대로 감지되지 않을 수 있다고함 => 유의하도록 하자

# 깊이 이해 (Depth understanding)
지원되는 기기의 기본 카메라를 사용하여 주어진 지점의 표면 간 거리 데이터를 포함하는 이미지를 생성하고, 
깊이 맵에서 제공하는 정보를 사용하여 좀 더 현실적으로 표현 가능
=> 이 내용은 ARCore을 사용하다보면 자연스레 이해될 듯 하다.

# 광원 추정 (Light estimation)
환경 조명을 감지하여 카메라 이미지를 보정하여 현실감이 커지게 한다.

# 사용자 상호작용 (User interaction)
ARCore는 조회 테스트를 사용하여 탭 (또는 앱에서 지원하려는 다른 상호작용으로 제공)에 해당하는 (x,y) 좌표를 가져와 카메라의 빛을 투영하고 
레이가 평면에서 교차하는 포즈와 함께 기하학적 평면 또는 특징점을 반환합니다. 
이를 통해 사용자는 환경에서 객체를 선택하거나 다른 요소와 상호작용할 수 있습니다.
=> 사용자가 화면을 탭하면 해당 x,y 좌표에 레이를 쏴서 레이가 교차(충돌?)하는 지점을 반환해준다고 생각하면 될 것 같다.

# 방향 포인트 (Oriented points)
방향 지점을 사용하면 비스듬한 표면에 가상 객체를 배치할 수 있다. 특성 포인트를 반환하는 적중 테스트를 실행하면 ARCore는 주변 특성 지점을 살펴보고 
이를 사용하여 지정된 특성 지점에서 표면의 각도를 추정한다. 그러면 ARCore에서 해당 각도를 고려하여 포즈를 반환한다.

ARCore는 특징점 클러스터를 사용하여 표면의 각도를 감지하므로 하얀 벽과 같은 질감이 없는 표면이 제대로 감지되지 않을 수 있다.

# 앵커 및 추적 가능 (Anchors and trackables)
ARCore의 위치 및 환경에 대한 이해를 높여 포즈를 변경할 수 있다. 가상 객체를 배치하려면 Anchor(본문 Core)를 정의하여 
ARCore가 시간이 지남에 따라 객체의 위치를 추적하도록 해야함. 

포즈가 변경될 수 있다는 것은 ARCore가 기하학적 평면 및 지형지물과 같은 환경객체의 위치를 시간이 지남에 따라 업데이트할 수 있음을 의미함.

평면 및 포인트는 추적 가능한(trackable)이라는 특수한 유형의 객체이며, 이름에서 알 수있듯이 시간이 지남에 따라 ARCore에서 추적하는 객체이다. 
가상 객체를 특정 trackable 대상에 고정하면 기기가 움직이는 경우에도 가상 객체와 추적 가능한 항목 간의 관계가 안정적으로 유지된다. 
예를 들어, 책상에 가상 Android 피규어를 배치하면 나중에 ARCore가책상과 연관된 기하학적 평면의 위치를 조정해도 
Android 피규어는 여전히 책상위에 있는것으로 표시된다.

# 증강 이미지 (Augmented Images)
특정 2D 이미지에 반응할 수 있게 하는 기능 
=> 카메라로 어떤 실제 오브젝트를 바라볼 때 무언가 튀어나온다거나...

# 공유 (Sharing)
ARCore Cloud Anchor API를 사용하면 Android 및 iOS 기기용 공동작업 또는 멀티플레이어 앱을 만들 수 있다.

Cloud 앵커를 사용하면 한 기기에서 호스팅을 위해 앵커 및 주변 기능 포인트를 클라우드로 전송한다. 

이 앵커는 동일한 환경의 Android 또는 iOS 기기에서 다른 사용자와 공유할 수 있다. 
이를 통해 앱은 앵커에 연결된 것과 동일한 3D 객체를 렌더링할 수 있어서, 사용자가 동시에 동일한 AR환경을 사용할 수 있다.